{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from utils import get_psnr, image_normalization\n",
    "from alignment.alignment_utils import load_deep_jscc\n",
    "from alignment.alignment_model import *\n",
    "from alignment.alignment_validation import *\n",
    "\n",
    "os.getcwd()\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fp = r'alignment/models/autoencoders/rayleigh_snr_-10_seed_42.pkl'\n",
    "# model1_fp = r'alignment/models/autoencoders/snr_0_seed_42.pkl'\n",
    "\n",
    "model2_fp = r'alignment/models/autoencoders/rayleigh_snr_-10_seed_43.pkl'\n",
    "# model2_fp = r'alignment/models/autoencoders/snr_0_seed_43.pkl'\n",
    "\n",
    "# aligner_fp = r'/home/lorenzo/repos/Deep-JSCC-PyTorch/alignment/models/plots/psnr_vs_pilots_5/aligner_mlp_10000.pkl'\n",
    "aligner_fp = r'/home/lorenzo/repos/Deep-JSCC-PyTorch/alignment/models/plots/psnr_vs_snr/aligner_twoconv_ae_-10_snr_0_seed_42.pth'\n",
    "\n",
    "snr = 0\n",
    "channel = \"Rayleigh\"\n",
    "image_path = r'demo/kodim23.png'\n",
    "# image_path = r'demo/0002.jpg'\n",
    "times = 10\n",
    "resolution = None\n",
    "upscale_factor = 1\n",
    "c = 8\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "no_mismatch_model, unaligned_model, aligned_model = prepare_models(model1_fp, model2_fp, aligner_fp, snr, c, resolution, channel, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without semantic mismatch\n",
    "visualization_pipeline(no_mismatch_model, image_path, resolution, times, upscale_factor)\n",
    "\n",
    "# with semantic mismatch, without aligning\n",
    "visualization_pipeline(unaligned_model, image_path, resolution, times, upscale_factor)\n",
    "\n",
    "# with semantic mismatch, with aligning\n",
    "visualization_pipeline(aligned_model, image_path, resolution, times, upscale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(model, output_path):\n",
    "    psnr_all = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(times):\n",
    "            demo_image = model(test_image)\n",
    "            demo_image = image_normalization('denormalization')(demo_image)\n",
    "            gt = image_normalization('denormalization')(test_image)\n",
    "            psnr_all += get_psnr(demo_image, gt)\n",
    "\n",
    "        # prepare image for visualization\n",
    "        demo_image = image_normalization('normalization')(demo_image)\n",
    "        demo_image = demo_image.squeeze()\n",
    "        demo_image = demo_image.numpy()  # (C, H, W)\n",
    "        demo_image = demo_image.transpose(1, 2, 0)  # convert to (H, W, C) for PIL\n",
    "\n",
    "        # convert to PIL image and upscale\n",
    "        pil_image = Image.fromarray((demo_image * 255).astype(np.uint8))\n",
    "        new_size = (pil_image.width * upscale_factor, pil_image.height * upscale_factor)\n",
    "        pil_image = pil_image.resize(new_size, Image.NEAREST)  # Use NEAREST or BICUBIC\n",
    "\n",
    "    # show the upscaled image\n",
    "    plt.figure(figsize=(new_size[0] / 100, new_size[1] / 100), dpi=100)\n",
    "    plt.imshow(pil_image)\n",
    "    plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    pil_image.save(output_path)\n",
    "\n",
    "    print(\"Average PSNR is {:.2f} over {} runs on {}\".format(psnr_all.item() / times, times, os.path.basename(test_image_dir)))\n",
    "\n",
    "for snr in [-20, -10, 0, 10, 20, 30]:\n",
    "    channel_type = 'AWGN'\n",
    "    model1_fp = f'alignment/models/autoencoders/upscaled_42.pkl'\n",
    "    model2_fp = f'alignment/models/autoencoders/upscaled_43.pkl'\n",
    "    aligner_fp = f'alignment/models/plots/high_res/aligner_twoconv_{snr}.pth'\n",
    "\n",
    "    test_image_dir = f'demo/kodim23.png'\n",
    "    times = 10\n",
    "    resolution = None\n",
    "    upscale_factor = 1\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    c = 8\n",
    "\n",
    "    if resolution is None:\n",
    "        transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "\n",
    "    else:\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((resolution, resolution))])\n",
    "\n",
    "    test_image = Image.open(test_image_dir)\n",
    "    test_image.load()\n",
    "    test_image = transform(test_image)\n",
    "\n",
    "    no_mismatch_model, unaligned_model, aligned_model = prepare_models(model1_fp, model2_fp, aligner_fp, snr, c, resolution, channel_type, device)\n",
    "\n",
    "    evaluation_pipeline(no_mismatch_model, f'alignment/models/plots/high_res/images/no_mismatch_{snr}.png')\n",
    "    evaluation_pipeline(unaligned_model, f'alignment/models/plots/high_res/images/unaligned_{snr}.png')\n",
    "    evaluation_pipeline(aligned_model, f'alignment/models/plots/high_res/images/aligned_{snr}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
